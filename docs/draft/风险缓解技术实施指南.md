# 充电桩网关风险缓解技术实施指南

## 1. 概述

本文档提供了针对充电桩网关架构风险的详细技术实施方案，包括代码示例、配置参数、测试方法等。

## 2. R001: 指令确认和重试机制实施

### 2.1 核心数据结构设计

```go
// 指令状态枚举
type CommandStatus int

const (
    CommandStatusPending CommandStatus = iota
    CommandStatusSent
    CommandStatusAcknowledged
    CommandStatusFailed
    CommandStatusExpired
)

// 带重试的指令结构
type CommandWithRetry struct {
    ID          string        `json:"id"`
    DeviceID    string        `json:"device_id"`
    Command     interface{}   `json:"command"`
    Status      CommandStatus `json:"status"`
    Attempts    int          `json:"attempts"`
    MaxAttempts int          `json:"max_attempts"`
    Timeout     time.Time    `json:"timeout"`
    CreatedAt   time.Time    `json:"created_at"`
    LastAttempt time.Time    `json:"last_attempt"`
    Error       string       `json:"error,omitempty"`
}

// 指令确认消息
type CommandAck struct {
    CommandID string `json:"command_id"`
    DeviceID  string `json:"device_id"`
    Status    string `json:"status"` // "success", "failed", "timeout"
    Error     string `json:"error,omitempty"`
    Timestamp time.Time `json:"timestamp"`
}
```

### 2.2 指令路由器实现

```go
type CommandRouter struct {
    redis       redis.Client
    kafka       kafka.Producer
    retryQueue  chan *CommandWithRetry
    ackTimeout  time.Duration
    maxRetries  int
    
    // 指令状态存储
    commandStore sync.Map // commandID -> *CommandWithRetry
    
    // 监控指标
    metrics *CommandMetrics
}

func NewCommandRouter(redis redis.Client, kafka kafka.Producer) *CommandRouter {
    cr := &CommandRouter{
        redis:      redis,
        kafka:      kafka,
        retryQueue: make(chan *CommandWithRetry, 1000),
        ackTimeout: 30 * time.Second,
        maxRetries: 3,
        metrics:    NewCommandMetrics(),
    }
    
    // 启动重试工作器
    go cr.retryWorker()
    go cr.timeoutChecker()
    
    return cr
}

func (cr *CommandRouter) SendCommand(deviceID string, cmd interface{}) error {
    cmdWithRetry := &CommandWithRetry{
        ID:          uuid.New().String(),
        DeviceID:    deviceID,
        Command:     cmd,
        Status:      CommandStatusPending,
        MaxAttempts: cr.maxRetries,
        Timeout:     time.Now().Add(cr.ackTimeout),
        CreatedAt:   time.Now(),
    }
    
    // 存储指令状态
    cr.commandStore.Store(cmdWithRetry.ID, cmdWithRetry)
    
    // 尝试发送
    return cr.attemptSend(cmdWithRetry)
}

func (cr *CommandRouter) attemptSend(cmd *CommandWithRetry) error {
    cmd.Attempts++
    cmd.LastAttempt = time.Now()
    cmd.Status = CommandStatusSent
    
    // 查询设备连接状态
    podID, err := cr.redis.Get(fmt.Sprintf("conn:%s", cmd.DeviceID)).Result()
    if err != nil {
        return cr.handleSendError(cmd, fmt.Errorf("device not connected: %w", err))
    }
    
    // 构造路由消息
    routedCmd := RoutedCommand{
        CommandID:   cmd.ID,
        TargetPodID: podID,
        DeviceID:    cmd.DeviceID,
        Command:     cmd.Command,
        Timestamp:   time.Now(),
    }
    
    // 发送到分片主题
    topic := cr.getShardTopic(podID)
    if err := cr.kafka.Produce(topic, routedCmd); err != nil {
        return cr.handleSendError(cmd, err)
    }
    
    cr.metrics.CommandsSent.Inc()
    return nil
}

func (cr *CommandRouter) handleSendError(cmd *CommandWithRetry, err error) error {
    cmd.Error = err.Error()
    cmd.Status = CommandStatusFailed
    
    if cmd.Attempts < cmd.MaxAttempts {
        // 加入重试队列
        select {
        case cr.retryQueue <- cmd:
            cr.metrics.CommandsRetried.Inc()
        default:
            cr.metrics.RetryQueueFull.Inc()
            return fmt.Errorf("retry queue full")
        }
    } else {
        // 超过最大重试次数，移入死信队列
        cr.moveToDeadLetter(cmd)
        cr.metrics.CommandsFailed.Inc()
    }
    
    return err
}
```

### 2.3 重试机制实现

```go
func (cr *CommandRouter) retryWorker() {
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case cmd := <-cr.retryQueue:
            // 指数退避
            backoff := time.Duration(cmd.Attempts) * time.Second
            time.Sleep(backoff)
            
            if err := cr.attemptSend(cmd); err != nil {
                log.Error().
                    Str("command_id", cmd.ID).
                    Str("device_id", cmd.DeviceID).
                    Int("attempts", cmd.Attempts).
                    Err(err).
                    Msg("Command retry failed")
            }
            
        case <-ticker.C:
            // 定期检查超时的指令
            cr.checkTimeouts()
        }
    }
}

func (cr *CommandRouter) checkTimeouts() {
    now := time.Now()
    
    cr.commandStore.Range(func(key, value interface{}) bool {
        cmd := value.(*CommandWithRetry)
        
        if cmd.Status == CommandStatusSent && now.After(cmd.Timeout) {
            cmd.Status = CommandStatusExpired
            cr.moveToDeadLetter(cmd)
            cr.commandStore.Delete(key)
            cr.metrics.CommandsExpired.Inc()
        }
        
        return true
    })
}
```

## 3. R002: Kafka主题优化实施

### 3.1 分片主题设计

```go
type ShardedCommandRouter struct {
    shardCount    int
    kafka         kafka.Producer
    consistentHash *consistent.Consistent
}

func NewShardedCommandRouter(shardCount int, kafka kafka.Producer) *ShardedCommandRouter {
    scr := &ShardedCommandRouter{
        shardCount:     shardCount,
        kafka:          kafka,
        consistentHash: consistent.New(),
    }
    
    // 初始化一致性哈希环
    for i := 0; i < shardCount; i++ {
        scr.consistentHash.Add(fmt.Sprintf("shard-%d", i))
    }
    
    return scr
}

func (scr *ShardedCommandRouter) getShardTopic(podID string) string {
    shard, _ := scr.consistentHash.Get(podID)
    return fmt.Sprintf("commands-down-%s", shard)
}

// 路由消息结构
type RoutedCommand struct {
    CommandID   string      `json:"command_id"`
    TargetPodID string      `json:"target_pod_id"`
    DeviceID    string      `json:"device_id"`
    Command     interface{} `json:"command"`
    Timestamp   time.Time   `json:"timestamp"`
    Priority    int         `json:"priority"` // 0=低, 1=正常, 2=高, 3=紧急
}
```

### 3.2 消息消费者实现

```go
type ShardedCommandConsumer struct {
    kafka       kafka.Consumer
    podID       string
    messageHandler MessageHandler
}

func (scc *ShardedCommandConsumer) Start(ctx context.Context) error {
    for {
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
            msg, err := scc.kafka.ReadMessage(ctx)
            if err != nil {
                continue
            }
            
            var routedCmd RoutedCommand
            if err := json.Unmarshal(msg.Value, &routedCmd); err != nil {
                log.Error().Err(err).Msg("Failed to unmarshal routed command")
                continue
            }
            
            // 检查是否是发给自己的消息
            if routedCmd.TargetPodID != scc.podID {
                continue // 忽略不是发给自己的消息
            }
            
            // 处理消息
            if err := scc.messageHandler.Handle(ctx, &routedCmd); err != nil {
                log.Error().
                    Str("command_id", routedCmd.CommandID).
                    Str("device_id", routedCmd.DeviceID).
                    Err(err).
                    Msg("Failed to handle command")
            }
        }
    }
}
```

## 4. R003: Redis连接状态管理实施

### 4.1 原子性连接注册

```go
type ConnectionRegistry struct {
    redis redis.Client
    ttl   time.Duration
}

func (cr *ConnectionRegistry) RegisterConnection(deviceID, podID string) error {
    key := fmt.Sprintf("conn:%s", deviceID)
    
    // Lua脚本确保原子性
    script := `
        local key = KEYS[1]
        local new_pod = ARGV[1]
        local ttl = tonumber(ARGV[2])
        local timestamp = tonumber(ARGV[3])
        
        -- 获取当前值
        local current = redis.call('HMGET', key, 'pod', 'timestamp', 'version')
        local current_pod = current[1]
        local current_timestamp = tonumber(current[2]) or 0
        local current_version = tonumber(current[3]) or 0
        
        -- 只有时间戳更新或者是新连接才允许更新
        if not current_pod or timestamp > current_timestamp then
            local new_version = current_version + 1
            redis.call('HMSET', key, 
                'pod', new_pod, 
                'timestamp', timestamp,
                'version', new_version,
                'status', 'connected')
            redis.call('EXPIRE', key, ttl)
            return {new_version, 'OK'}
        else
            return {current_version, 'CONFLICT'}
        end
    `
    
    result, err := cr.redis.Eval(script, []string{key}, 
        podID, int(cr.ttl.Seconds()), time.Now().Unix()).Result()
    
    if err != nil {
        return fmt.Errorf("failed to register connection: %w", err)
    }
    
    resultSlice := result.([]interface{})
    status := resultSlice[1].(string)
    
    if status == "CONFLICT" {
        return fmt.Errorf("connection registration conflict for device %s", deviceID)
    }
    
    return nil
}

func (cr *ConnectionRegistry) UnregisterConnection(deviceID, podID string) error {
    key := fmt.Sprintf("conn:%s", deviceID)
    
    script := `
        local key = KEYS[1]
        local expected_pod = ARGV[1]
        
        local current_pod = redis.call('HGET', key, 'pod')
        if current_pod == expected_pod then
            redis.call('DEL', key)
            return 'OK'
        else
            return 'NOT_OWNER'
        end
    `
    
    result, err := cr.redis.Eval(script, []string{key}, podID).Result()
    if err != nil {
        return fmt.Errorf("failed to unregister connection: %w", err)
    }
    
    if result == "NOT_OWNER" {
        return fmt.Errorf("pod %s is not the owner of device %s", podID, deviceID)
    }
    
    return nil
}
```

### 4.2 连接状态监控

```go
func (cr *ConnectionRegistry) StartHealthChecker(ctx context.Context) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            cr.checkConnectionHealth()
        }
    }
}

func (cr *ConnectionRegistry) checkConnectionHealth() {
    // 扫描所有连接
    keys, err := cr.redis.Keys("conn:*").Result()
    if err != nil {
        log.Error().Err(err).Msg("Failed to scan connection keys")
        return
    }
    
    for _, key := range keys {
        deviceID := strings.TrimPrefix(key, "conn:")
        
        // 检查连接是否过期
        ttl, err := cr.redis.TTL(key).Result()
        if err != nil {
            continue
        }
        
        if ttl < 10*time.Second {
            log.Warn().
                Str("device_id", deviceID).
                Duration("ttl", ttl).
                Msg("Connection TTL is low")
        }
    }
}
```

## 5. 监控指标实现

```go
type GatewayMetrics struct {
    // 连接指标
    ActiveConnections   prometheus.Gauge
    ConnectionsTotal    prometheus.Counter
    ConnectionErrors    prometheus.Counter
    
    // 指令指标
    CommandsSent        prometheus.Counter
    CommandsAcknowledged prometheus.Counter
    CommandsFailed      prometheus.Counter
    CommandsRetried     prometheus.Counter
    CommandsExpired     prometheus.Counter
    
    // 性能指标
    MessageProcessTime  prometheus.Histogram
    CommandLatency      prometheus.Histogram
    
    // 错误指标
    RedisErrors         prometheus.Counter
    KafkaErrors         prometheus.Counter
}

func NewGatewayMetrics() *GatewayMetrics {
    return &GatewayMetrics{
        ActiveConnections: prometheus.NewGauge(prometheus.GaugeOpts{
            Name: "gateway_active_connections",
            Help: "Number of active WebSocket connections",
        }),
        CommandsSent: prometheus.NewCounter(prometheus.CounterOpts{
            Name: "gateway_commands_sent_total",
            Help: "Total number of commands sent",
        }),
        MessageProcessTime: prometheus.NewHistogram(prometheus.HistogramOpts{
            Name: "gateway_message_process_duration_seconds",
            Help: "Time spent processing messages",
            Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0},
        }),
    }
}
```

## 6. 测试策略

### 6.1 单元测试
- 指令路由逻辑测试
- Redis操作原子性测试
- 重试机制测试

### 6.2 集成测试
- 故障转移场景测试
- 高并发压力测试
- 网络分区测试

### 6.3 混沌工程
- 随机Pod故障注入
- 网络延迟注入
- Redis故障模拟

---

**实施优先级**: 按风险等级依次实施  
**预计工期**: 第一阶段2个月，第二阶段2个月  
**成功标准**: 通过所有测试用例，满足性能指标
